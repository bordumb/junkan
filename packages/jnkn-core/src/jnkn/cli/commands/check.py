"""
Check Command - CI/CD Gate for Pre-Merge Impact Analysis.

This module implements the logic to verify changes against the dependency graph.
It acts as the primary gatekeeper in CI/CD pipelines.
"""

import logging
import re
import subprocess
import sys
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, List, Tuple

import click
from pydantic import BaseModel, Field
from rich.console import Console

from ...analysis.blast_radius import BlastRadiusAnalyzer
from ...analysis.top_findings import FindingType, TopFindingsExtractor
from ...core.manifest import ProjectManifest
from ...core.resolver import DependencyResolver
from ...core.stitching import Stitcher
from ...core.storage.sqlite import SQLiteStorage
from ...core.types import NodeType
from ...parsing.engine import ScanConfig, create_default_engine
from ..renderers import JsonRenderer
from ..utils import SKIP_DIRS, load_graph

logger = logging.getLogger(__name__)
console = Console(stderr=True)  # Use stderr for logs to not pollute JSON output pipes


# --- API Models (External Contract) ---
class CheckResultStatus(str, Enum):
    PASS = "PASS"
    BLOCKED = "BLOCKED"
    WARN = "WARN"


class ApiViolation(BaseModel):
    rule: str
    severity: str
    message: str


class CheckResponse(BaseModel):
    """
    Standardized response for check command.
    """

    result: CheckResultStatus
    exit_code: int
    changed_files_count: int
    critical_count: int
    high_count: int
    violations: List[ApiViolation] = Field(default_factory=list)


# --- Internal Domain Models ---
class CheckResult(Enum):
    PASS = 0
    BLOCKED = 1
    WARN = 2


@dataclass
class ChangedFile:
    path: str
    change_type: str  # 'A', 'M', 'D', etc.
    old_path: str | None = None


@dataclass
class CheckReport:
    """Internal report generated by the analysis engine."""

    result: CheckResult = CheckResult.PASS
    changed_files: List[ChangedFile] = field(default_factory=list)
    critical_count: int = 0
    high_count: int = 0
    violations: List[Any] = field(default_factory=list)


class CheckEngine:
    """
    Performs risk assessment on changed files using the dependency graph.
    """

    def __init__(self, graph_path: str = ".jnkn/jnkn.db"):
        self.graph_path = graph_path
        self.graph = load_graph(graph_path)

    def ensure_graph_exists(self, force_scan: bool = False):
        """
        Auto-scan capability: If graph is missing, build it on the fly.
        This enables the 'init -> check' workflow without an explicit 'scan' step.
        """
        if not force_scan and self.graph is not None and self.graph.node_count > 0:
            return

        console.print("[dim]Graph not found or empty. Running auto-scan...[/dim]")

        # Setup paths
        db_path = Path(self.graph_path)
        root_dir = Path.cwd()

        # Initialize components
        engine = create_default_engine()
        storage = SQLiteStorage(db_path)
        storage.clear()

        # 1. Resolve Dependencies (Phase 1)
        scan_targets = [(root_dir, ProjectManifest.load(root_dir / "jnkn.toml").name)]

        try:
            resolver = DependencyResolver(root_dir)
            resolution = resolver.resolve()
            for dep in resolution.dependencies:
                scan_targets.append((dep.path, dep.name))
        except Exception as e:
            console.print(f"[yellow]Warning: Dependency resolution failed: {e}[/yellow]")

        # 2. Scan all targets
        for target_path, repo_name in scan_targets:
            if not target_path.exists():
                continue

            config = ScanConfig(
                root_dir=target_path,
                skip_dirs=SKIP_DIRS,
                incremental=False,
                source_repo_name=repo_name,
            )
            result = engine.scan_and_store(storage, config)

            if result.is_err():
                console.print(
                    f"[red]Scan failed for {repo_name}:[/red] {result.unwrap_err().message}"
                )

        # 3. Stitch
        graph = storage.load_graph()
        stitcher = Stitcher()
        new_edges = stitcher.stitch(graph)
        storage.save_edges_batch(new_edges)

        # 4. Reload
        self.graph = storage.load_graph()
        storage.close()
        console.print(f"[dim]Auto-scan complete. Found {self.graph.node_count} nodes.[/dim]")

    def analyze(self, changes: List[ChangedFile]) -> CheckReport:
        # Ensure we have data to analyze
        self.ensure_graph_exists()

        report = CheckReport(changed_files=changes)

        if not self.graph:
            self._analyze_static(changes, report)
            return report

        analyzer = BlastRadiusAnalyzer(self.graph)
        findings_extractor = TopFindingsExtractor(self.graph)

        # 1. Check for global issues (like missing providers)
        findings = findings_extractor.extract()

        if findings.missing_providers > 0:
            for finding in findings.findings:
                # Check against enum value or string for robustness
                is_missing = (
                    finding.type == FindingType.MISSING_PROVIDER
                    or finding.type == "missing_provider"
                )

                if is_missing:
                    report.violations.append(
                        ApiViolation(
                            rule="MISSING_PROVIDER", severity="critical", message=finding.title
                        )
                    )
                    report.critical_count += 1

        for file in changes:
            # 2. Resolve file to graph node
            node_id = f"file://{file.path}"

            # Safety Net: Explicitly check for orphans in this file
            associated_nodes = [
                n for n in self.graph.iter_nodes() if n.path and str(n.path).endswith(file.path)
            ]

            for node in associated_nodes:
                if node.type == NodeType.ENV_VAR:
                    out_edges = self.graph.get_out_edges(node.id)
                    has_infra = any(e.target_id.startswith("infra:") for e in out_edges)
                    if not has_infra:
                        already_reported = any(
                            v.message.startswith(node.name) for v in report.violations
                        )
                        if not already_reported:
                            report.violations.append(
                                ApiViolation(
                                    rule="MISSING_PROVIDER",
                                    severity="critical",
                                    message=f"{node.name} has no infrastructure provider",
                                )
                            )
                            report.critical_count += 1

            if not self.graph.has_node(node_id):
                self._analyze_single_file_heuristic(file, report)
                continue

            # 3. Calculate Impact
            impact = analyzer.calculate([node_id])
            impact_count = impact.get("count", 0)

            # 4. Apply Rules
            if impact_count > 20:
                report.violations.append(
                    ApiViolation(
                        rule="HIGH_BLAST_RADIUS",
                        severity="high",
                        message=f"{file.path} impacts {impact_count} downstream artifacts.",
                    )
                )
                report.high_count += 1

            # Rule: Critical Node Modification
            downstream = self.graph.get_descendants(node_id)
            for target_id in downstream:
                target = self.graph.get_node(target_id)
                if target and target.type == NodeType.INFRA_RESOURCE:
                    report.violations.append(
                        ApiViolation(
                            rule="INFRA_IMPACT",
                            severity="critical",
                            message=f"Change to {file.path} impacts infrastructure {target.name}",
                        )
                    )
                    report.critical_count += 1
                    break

        return report

    def _analyze_static(self, changes: List[ChangedFile], report: CheckReport):
        """Fallback analysis when no graph is available."""
        for file in changes:
            self._analyze_single_file_heuristic(file, report)

    def _analyze_single_file_heuristic(self, file: ChangedFile, report: CheckReport):
        """Heuristic checks based purely on filenames."""
        path = file.path.lower()

        if any(x in path for x in ["/tests/", "/fixtures/", "/corpus/", "/test/"]):
            return

        if path.endswith((".tf", ".tfvars", ".hcl")):
            report.violations.append(
                ApiViolation(
                    rule="INFRA_CHANGE",
                    severity="critical",
                    message=f"Infrastructure change detected: {file.path}",
                )
            )
            report.critical_count += 1

        elif "migrations" in path or "schema" in path or path.endswith(".sql"):
            report.violations.append(
                ApiViolation(
                    rule="SCHEMA_CHANGE",
                    severity="high",
                    message=f"Data schema change detected: {file.path}",
                )
            )
            report.high_count += 1


def get_changed_files_from_git(base_ref: str, head_ref: str) -> List[ChangedFile]:
    """Get changed files between two git refs using git diff."""
    try:
        result = subprocess.run(
            ["git", "diff", "--name-status", base_ref, head_ref],
            capture_output=True,
            text=True,
            check=True,
        )
    except subprocess.CalledProcessError:
        return []

    changes = []
    for line in result.stdout.splitlines():
        if not line.strip():
            continue
        parts = line.split("\t")
        status = parts[0][0]
        if status == "R":
            if len(parts) >= 3:
                changes.append(ChangedFile(path=parts[2], change_type="RENAME", old_path=parts[1]))
        else:
            changes.append(ChangedFile(path=parts[1], change_type=status))
    return changes


def get_changed_files_from_diff_file(diff_path: str) -> List[ChangedFile]:
    """Parse a standard Unified Diff file."""
    changes = []
    path = Path(diff_path)
    content = path.read_text()
    diff_pattern = re.compile(r"^diff --git a/(.*?) b/(.*?)$", re.MULTILINE)
    for match in diff_pattern.finditer(content):
        changes.append(ChangedFile(path=match.group(2), change_type="MODIFIED"))
    return changes


class _null_context:
    def __enter__(self):
        pass

    def __exit__(self, *args):
        pass


@click.command()
@click.option(
    "--diff", "diff_file", type=click.Path(exists=True), help="Path to a unified diff file"
)
@click.option("--git-diff", "git_diff", nargs=2, help="Git refs to compare (BASE HEAD)")
@click.option(
    "--ignore-critical",
    is_flag=True,
    help="Do NOT exit with error even if critical violations found",
)
@click.option("--json", "as_json", is_flag=True, help="Output as JSON (Standard Envelope)")
@click.option("--format", "output_format", type=click.Choice(["text", "markdown"]), default="text")
@click.option("--quiet", "-q", is_flag=True, help="Suppress text output")
def check(
    diff_file: str | None,
    git_diff: Tuple[str, str] | None,
    ignore_critical: bool,
    as_json: bool,
    output_format: str,
    quiet: bool,
):
    """
    Run pre-merge impact analysis.

    Compares changes against the dependency graph to detect breaking changes.
    Will automatically scan the codebase if no graph exists.
    """
    renderer = JsonRenderer("check")
    context_manager = renderer.capture() if as_json else _null_context()
    error_to_report = None
    api_response = None
    fail_on_critical = not ignore_critical  # Default to Safe (Fail on critical)

    with context_manager:
        try:
            changed_files = []
            if diff_file:
                changed_files = get_changed_files_from_diff_file(diff_file)
            elif git_diff:
                base, head = git_diff
                changed_files = get_changed_files_from_git(base, head)
            else:
                try:
                    changed_files = get_changed_files_from_git("HEAD~1", "HEAD")
                except Exception:
                    pass

            engine = CheckEngine()
            # Force scan if we have no changes (e.g. fresh repo) to ensure graph is built
            if not changed_files and not engine.graph:
                engine.ensure_graph_exists(force_scan=True)

            report = engine.analyze(changed_files)

            if fail_on_critical and report.critical_count > 0:
                report.result = CheckResult.BLOCKED
            elif report.high_count > 5:
                report.result = CheckResult.WARN

            api_violations = [
                ApiViolation(rule=v.rule, severity=v.severity, message=v.message)
                for v in report.violations
            ]

            api_response = CheckResponse(
                result=CheckResultStatus[report.result.name],
                exit_code=report.result.value,
                changed_files_count=len(report.changed_files),
                critical_count=report.critical_count,
                high_count=report.high_count,
                violations=api_violations,
            )

        except Exception as e:
            error_to_report = e

    if as_json:
        if error_to_report:
            renderer.render_error(error_to_report)
            sys.exit(1)
        elif api_response:
            renderer.render_success(api_response)
            sys.exit(api_response.exit_code)
    else:
        if error_to_report:
            if not quiet:
                console.print(f"‚ùå [red]Error:[/red] {error_to_report}")
            sys.exit(1)

        if api_response:
            color = "green"
            if api_response.result == CheckResultStatus.BLOCKED:
                color = "red"
            elif api_response.result == CheckResultStatus.WARN:
                color = "yellow"

            if not quiet:
                if api_response.violations:
                    console.print(
                        f"\n[bold]Analysis Complete:[/bold] {len(api_response.violations)} violations found."
                    )
                    for v in api_response.violations:
                        icon = (
                            "üî¥"
                            if v.severity == "critical"
                            else "üü†"
                            if v.severity == "high"
                            else "‚ö™"
                        )
                        console.print(f"  {icon} [{v.severity.upper()}] {v.message}")
                else:
                    console.print("\nAnalysis Complete: 0 violations found.")

                console.print(f"\nResult: [bold {color}]{api_response.result.value}[/bold {color}]")

            sys.exit(api_response.exit_code)
